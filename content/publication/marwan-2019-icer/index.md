---
# Documentation: https://wowchemy.com/docs/managing-content/

title: An Evaluation of the Impact of Automated Programming Hints on Performance and
  Learning
subtitle: ''
summary: ''
authors:
- Samiha Marwan
- Joseph Jay Williams
- Thomas Price
tags:
- Peer Reviewed Conference Paper (Full)
categories: []
date: '2019-01-01'
lastmod: 2021-07-07T11:39:51-04:00
featured: false
draft: false
url_pdf: papers/MarwanICER2019.pdf

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:
- isnap
publishDate: '2021-07-07T15:39:50.904637Z'
publication_types:
- '1'
abstract: "A growing body of work has explored how to automatically generate hints\
  \ for novice programmers, and many programming environments now employ these hints.\
  \ However, few studies have investigated the efficacy of automated programming hints\
  \ for improving performance and learning, how and when novices find these hints\
  \ beneficial, and the tradeoffs that exist between different types of hints. In\
  \ this work, we explored the efficacy of next-step code hints with 2 complementary\
  \ features: textual explanations and self-explanation prompts. We conducted two\
  \ studies in which novices completed two programming tasks in a block-based programming\
  \ environment with automated hints. In Study 1, 10 undergraduate students completed\
  \ 2 programming tasks with a variety of hint types, and we interviewed them to understand\
  \ their perceptions of the affordances of each hint type. For Study 2, we recruited\
  \ a convenience sample of participants without programming experience from Amazon\
  \ Mechanical Turk. We conducted a randomized experiment comparing the effects of\
  \ hints' types on learners' performance and performance on a subsequent task without\
  \ hints. We found that code hints with textual explanations significantly improved\
  \ immediate programming performance. However, these hints only improved performance\
  \ in a subsequent post-test task with similar objectives, when they were combined\
  \ with self-explanation prompts. These results provide design insights into how\
  \ automatically generated code hints can be improved with textual explanations and\
  \ prompts to self-explain, and provide evidence about when and how these hints can\
  \ improve programming performance and learning."
publication: '*Proceedings of the International Computing Education Research Conference*'
doi: 10.1145/3291279.3339420
---
